{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b546a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount drive and cd to notebook folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "%cd \"/content/drive/MyDrive/pato/upf-smc/thesis/rhythmic-relationships/scripts\"\n",
    "\n",
    "import sys\n",
    "COLAB_WORKDIR = \"/content/drive/MyDrive/pato/upf-smc/thesis/rhythmic-relationships/scripts\"\n",
    "if COLAB_WORKDIR not in sys.path:\n",
    "  sys.path.append(COLAB_WORKDIR)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -Par ../../datasets/lmdc_17243_2bar_4res/ /tmp/lmdc_17243_2bar_4res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c501fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install --upgrade pip -qq\n",
    "!pip install .. -qq\n",
    "!pip install git+https://github.com/danielgomezmarin/rhythmtoolbox -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791009f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from model_utils import get_model_name, load_config, save_model, get_loss_fn\n",
    "from rhythmic_relationships.data import PartDatasetSequential\n",
    "from rhythmic_relationships.model import TransformerDecoder\n",
    "from rhythmic_relationships.train import train_transformer_decoder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "DEVICE = torch.device('cuda:0')\n",
    "CONFIG_FILEPATH = \"transformer_decoder_config.yml\"\n",
    "\n",
    "\n",
    "config = load_config(CONFIG_FILEPATH)\n",
    "\n",
    "# Overwrite hyperparameters\n",
    "config['dataset'] = {\n",
    "  \"dataset_name\": \"lmdc_17243_2bar_4res\",\n",
    "  \"part\": \"Bass\",\n",
    "  \"representation\": \"onset_roll\",\n",
    "  \"context_len\": 31,\n",
    "}\n",
    "config['model'] = {\n",
    "  'vocab_size': 130,\n",
    "  'n_embed': 64,\n",
    "  'n_head': 2,\n",
    "  'n_layer': 3,\n",
    "  'dropout': 0.3,\n",
    "}\n",
    "config['sequence_len'] = 32\n",
    "config['resolution'] = 4\n",
    "config['loss_fn'] = 'cross-entropy'\n",
    "config['loss_reduction'] = 'mean'\n",
    "config['clip_gradients'] = False\n",
    "config['num_epochs'] = 15\n",
    "config['batch_size'] = 256\n",
    "config['lr'] = 1e-3\n",
    "config['wandb'] = False\n",
    "config['n_eval_iters'] = 20\n",
    "config['n_eval_seqs'] = 100\n",
    "config['splits']['train'] = 0.8\n",
    "config['splits']['val'] = 0.1\n",
    "config['splits']['test'] = 0.1\n",
    "config['seed'] = 13\n",
    "\n",
    "\n",
    "print(yaml.dump(config))\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "dataset = PartDatasetSequential(**config[\"dataset\"], datasets_dir='/tmp')\n",
    "splits = config[\"splits\"]\n",
    "train_data, val_data, test_data = random_split(dataset, list(splits.values()))\n",
    "print(f\"{splits=}: {len(train_data)}, {len(val_data)}, {len(test_data)}\")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "model_name = get_model_name()\n",
    "print(f\"{model_name=}\")\n",
    "\n",
    "config[\"model\"][\"context_len\"] = config[\"dataset\"][\"context_len\"]\n",
    "model = TransformerDecoder(**config[\"model\"]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "loss_fn = get_loss_fn(config)\n",
    "\n",
    "epoch_evals = train_transformer_decoder(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    config=config,\n",
    "    device=DEVICE,\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "# Save the stats for the last epoch\n",
    "stats = {\n",
    "    \"epoch_evals\": epoch_evals,\n",
    "    \"n_params\": sum(p.nelement() for p in model.parameters()),\n",
    "}\n",
    "print(stats)\n",
    "\n",
    "save_model(model, config, model_name, stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
