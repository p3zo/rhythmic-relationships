{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d72b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from model_utils import get_model_name, load_config, save_model\n",
    "from rhythmic_relationships.data import PartDataset\n",
    "from rhythmic_relationships.model import VAE\n",
    "from rhythmic_relationships.train import train\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rhythmic_relationships import MODELS_DIR, CHECKPOINTS_DIRNAME\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "CONFIG_FILEPATH = \"part_vae_config.yml\"\n",
    "\n",
    "\n",
    "def compute_loss(recons, x, mu, sigma, loss_fn):\n",
    "    reconstruction_loss = loss_fn(recons, x)\n",
    "    kld_loss = torch.mean(\n",
    "        -0.5 * torch.sum(1 + sigma - mu**2 - sigma.exp(), dim=1), dim=0\n",
    "    )\n",
    "    return reconstruction_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a8cc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = get_model_name()\n",
    "print(f\"{model_name=}\\n\")\n",
    "\n",
    "config = load_config(CONFIG_FILEPATH)\n",
    "print(yaml.dump(config))\n",
    "\n",
    "device = DEVICE\n",
    "x_dim = config[\"model\"][\"x_dim\"]\n",
    "y_dim = config[\"model\"][\"y_dim\"]\n",
    "clip_gradients = config[\"clip_gradients\"]\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "\n",
    "dataset = PartDataset(**config[\"dataset\"])\n",
    "loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "model = VAE(**config[\"model\"]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "reduction = config[\"loss_reduction\"]\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "\n",
    "print('----\\nLayers\\n')\n",
    "for lname, l in model._modules.items():\n",
    "    print('  ', lname, l)\n",
    "\n",
    "print('----\\nParameters\\n')\n",
    "n_params = 0\n",
    "for pname, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print('  ', pname, param.nelement())\n",
    "        n_params += param.nelement()\n",
    "\n",
    "print(f'\\nTotal number of parameters: {n_params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "log_losses = []\n",
    "ud = [] # update:data ratio\n",
    "\n",
    "for i, x in enumerate(loader):\n",
    "    # Forward pass\n",
    "    x = x.to(device).view(x.shape[0], x_dim)\n",
    "    x_binary = (x > 0).to(torch.float32)\n",
    "    x_recon, mu, sigma = model(x_binary)\n",
    "\n",
    "    # Compute loss\n",
    "    x_recon_binary = (x_recon > 0).to(torch.float32)\n",
    "    onset_loss = compute_loss(x_recon_binary, x_binary, mu, sigma, loss_fn)\n",
    "    velocity_loss = compute_loss(x_recon, x, mu, sigma, loss_fn)\n",
    "    loss = onset_loss + velocity_loss\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    if clip_gradients:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    log_losses.append(loss.log10().item())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{i:4d}/{len(loader)}: {loss.log10().item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ud.append(\n",
    "            [((config[\"lr\"] * p.grad).std() / p.data.std()).log10().item() for p in model.parameters()]\n",
    "        )\n",
    "    break\n",
    "print(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check neuron activations in each linear layer\n",
    "# We want to make sure that no column is all 0s, because that would indicate a dead neuron\n",
    "linear_layers = [i for i in model.encoder if isinstance(i, torch.nn.Linear)]\n",
    "n_layers = len(linear_layers)\n",
    "\n",
    "fig, ax = plt.subplots(1, n_layers, figsize=(10, 2))\n",
    "for ix, layer in enumerate(linear_layers):\n",
    "    abs_weights = layer.weight.detach().cpu().numpy()\n",
    "    ax[ix].imshow(abs_weights > 0, cmap='gray', interpolation='nearest');\n",
    "    ax[ix].set_title(str(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.encoder[0].weight.view(-1).detach().cpu().numpy().tolist(), 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_losses);\n",
    "# plt.plot(torch.tensor(training_losses).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aff9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "\n",
    "for ix, layer in enumerate(model.encoder):\n",
    "    t = layer.\n",
    "    if isinstance(i, torch.nn.ReLU):\n",
    "        print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (ix, t.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer {ix} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1073607",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "\n",
    "print(f'---\\nTotal number of parameters: {n_params}')\n",
    "for i, (pname, p) in enumerate(model.named_parameters()):\n",
    "    if p.ndim == 2:\n",
    "        plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "        legends.append('param %d' % i)\n",
    "# Stanford CS231n states that the ratio of weights:updates should be roughly 1e-3\n",
    "# See https://cs231n.github.io/neural-networks-3/#ratio\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k')\n",
    "plt.legend(legends);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805e534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
